<!-- THIS IS AN AUTOMATICALLY GENERATED FILE.  DO NOT EDIT THIS FILE! -->

<html> <head>
<title>Papers by Tom Minka</title>
</head>

<body>
<h1>Papers by Tom Minka (also available <a href="index.html">by topic</a>)</h1>

Expectation propagation
<br>&nbsp;|&nbsp;&nbsp;
Bayesian methods
<br>&nbsp;|&nbsp;&nbsp; |&nbsp;&nbsp;
Probabilistic modeling
<br>&nbsp;|&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp;
Optimization
<br>&nbsp;|&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp;
Text retrieval
<br>&nbsp;|&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp;
Computer vision
<br>&nbsp;|&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp; |&nbsp;&nbsp;
|&nbsp;&nbsp; |&nbsp;&nbsp;

<table hspace="0">

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2018</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/trueskill-2-improved-bayesian-skill-rating-system/">TrueSkill 2: An improved Bayesian skill rating system</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2017</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/belief-propagation-strings/">Belief Propagation with Strings</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2015</td>
<td><a href="http://sms.cam.ac.uk/media/2132075">An introduction to Expectation Propagation (video lecture)</a> <a href="MinkaMaterialsTutorial.pdf">(slides)</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2014</td>
<td><a href="http://stanford.edu/~rezab/nips2014workshop/submits/distbayes.pdf">Elastic Distributed Bayesian Collaborative Filtering</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2014</td>
<td><a href="http://papers.nips.cc/paper/5449-a-sampling">A* Sampling</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2014</td>
<td><a href="http://www.cs.toronto.edu/~dtarlow/NCAAF.pdf">Knowing what we don't know in NCAA Football ratings: Understanding and using structured uncertainty</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2013</td>
<td><a href="http://arxiv.org/abs/1312.5386">Detecting Parameter Symmetries in Probabilistic Models</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2012</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/how-to-grade-a-test-without-knowing-the-answers-a-bayesian-graphical-model-for-adaptive-crowdsourcing-and-aptitude-testing/">A Bayesian Graphical Model for Adaptive Crowdsourcing and Aptitude Testing</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2012</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/spot-localization-using-phy-layer-information/">Spot Localization using PHY Layer Information</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2011</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/non-conjugate-variational-message-passing-for-multinomial-and-binary-regression/">Non-conjugate Variational Message Passing for Multinomial and Binary Regression</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2010</td>
<td><a href="http://www.microsoft.com/en-us/research/publication/sparse-posterior-gaussian-processes-for-general-likelihoods/">Sparse-posterior Gaussian Processes for general likelihoods</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td>M</td>
<td></td>
<td>T</td>
<td></td>
<td>2010</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/a-novel-click-model-and-its-applications-to-online-advertising/">A Novel Click Model and Its Applications to Online Advertising</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2009</td>
<td><a href="mlss2009/">Probabilistic Programming with Infer.NET</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2009</td>
<td><a href="http://videolectures.net/mlss09uk_minka_ai/">Video lectures on Approximate Inference</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2009</td>
<td><a href="imps2009/">Automating variational inference for statistics and data mining</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2009</td>
<td><a href="http://arxiv.org/abs/1205.2623">Virtual Vector Machine for Bayesian Online Classification</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td>M</td>
<td></td>
<td>T</td>
<td></td>
<td>2009</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/click-chain-model-in-web-search/">Click Chain Model in Web Search</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2008</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/gates-a-graphical-notation-for-mixture-models/">Gates: A graphical notation for mixture models</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T</td>
<td></td>
<td>2008</td>
<td><a href="minka-letor-datasets.pdf">Selection bias in the LETOR datasets</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>2008</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/bayesian-color-constancy-revisited/">Bayesian Color Constancy Revisited</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T</td>
<td></td>
<td>2008</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/softrank-optimising-non-smooth-rank-metrics/">SoftRank: Optimising Non-Smooth Ranking Metrics</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2007</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/trueskill-through-time-revisiting-the-history-of-chess/">TrueSkill Through Time: Revisiting the History of Chess</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td>T</td>
<td></td>
<td>2007</td>
<td><a href="http://www.cs.cmu.edu/~nmramesh/sd_tc.pdf">The Smoothed Dirichlet distribution: A new building block for generative topical models</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2006</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/trueskilltm-a-bayesian-skill-rating-system/">TrueSkill: A Bayesian Skill Rating System</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td>O</td>
<td></td>
<td></td>
<td>2006</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/local-training-and-belief-propagation/">Local Training and Belief Propagation</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2006</td>
<td><a href="http://people.csail.mit.edu/alanqi/papers/Qi_Minka_Dynamic_EP_Signal_Detection_Preprint.pdf">Window-based expectation propagation for adaptive signal detection in flat-fading channels</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td>O</td>
<td></td>
<td>V</td>
<td>2006</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/cosegmenting-image-pairs-by-matching-global-histograms/">Cosegmentation of Image Pairs by Histogram Matching - Incorporating a Global Constraint into MRFs</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td>V</td>
<td>2006</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/principled-hybrids-of-generative-and-discriminative-models/">Principled Hybrids of Generative and Discriminative Models</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2005</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/discriminative-models-not-discriminative-training/">Discriminative models, not discriminative training</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>2005</td>
<td><a href="Winn-VisualDictionary.pdf">Object Categorization by Learned Universal Visual Dictionary</a></td>
<td><font size="-1">A Bayesian version of agglomerative information bottleneck.</font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2005</td>
<td><a href="srg/">Structured Region Graphs: Morphing EP into GBP</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2005</td>
<td><a href="message-passing/">Divergence measures and message passing</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2005</td>
<td><a href="bcrf/">Bayesian Conditional Random Fields</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2004</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/power-ep/">Power EP</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2004</td>
<td><a href="ep/roadmap.html">A roadmap to research on EP</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2004</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/predictive-automatic-relevance-determination-expectation-propagation/">Predictive Automatic
Relevance Determination by Expectation Propagation</a></td>
<td><font size="-1">Preventing overfitting in ARD.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td>V</td>
<td>2004</td>
<td><a href="https://www.microsoft.com/en-us/research/publication/exemplar-based-likelihoods-using-the-pdf-projection-theorem/">Exemplar-based likelihoods using the PDF projection theorem</a></td>
<td><font size="-1">How to properly normalize distributions over image features.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td>T</td>
<td>V</td>
<td>2003</td>
<td><a href="minka-summation.pdf">The `summation hack' as an outlier model</a></td>
<td><font size="-1">An explanation of a common trick used in computer vision and text retrieval.</font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="eptree/">Tree-structured approximations by expectation
propagation</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="infinite/">Expectation Propagation for Infinite
Mixtures</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>2003</td>
<td><a href="http://www-2.cs.cmu.edu/~chuck/nips-2003/">Bayesian Color
Constancy with Non-Gaussian Models</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="http://vismod.media.mit.edu/tech-reports/TR-555-ABSTRACT.html">Expectation Propagation for Signal Detection in Flat-fading Channels</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="viz.html">Building statistical models by visualization</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="http://ba.stat.cmu.edu/journal/2006/vol01/issue02/kadane363-374.pdf">Conjugate Analysis of the Conway-Maxwell-Poisson Distribution</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="http://www.ingentaconnect.com/content/bpl/rssc/2005/00000054/00000001/art00009">A Useful Distribution for Fitting Discrete Data: Revival of the COM-Poisson</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="http://www.stat.cmu.edu/tr/tr776/tr776.html">Computing with the COM-Poisson distribution</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td>O</td>
<td></td>
<td></td>
<td>2002</td>
<td><a href="minka-gamma.pdf">Estimating a Gamma distribution</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2002</td>
<td><a href="qi-minka-HMH-AMIT-02.pdf">Hessian-based Markov Chain Monte-Carlo Algorithms</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2002</td>
<td><a href="dynamic.html">Bayesian inference in dynamic models -- an overview</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>2002</td>
<td><a href="minka-errorbars.pdf">Judging significance from error bars</a></td>
<td><font size="-1">Something everyone should know how to do, but probably doesn't.</font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2002</td>
<td><a href="http://www.cs.purdue.edu/homes/alanqi/papers/qi-spec-02.pdf">Bayesian Spectrum
Estimation of Unevenly Sampled Nonstationary Data</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T</td>
<td></td>
<td>2002</td>
<td><a href="http://www-2.cs.cmu.edu/~yiz/research.htm">Novelty and Redundancy Detection in Adaptive Filtering</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td>T</td>
<td></td>
<td>2002</td>
<td><a href="aspect/">Expectation-Propagation for the Generative Aspect Model</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td>O</td>
<td></td>
<td></td>
<td>2003</td>
<td><a href="logreg/">A comparison of numerical optimizers for logistic regression</a></td>
<td><font size="-1">Derives and compares eight methods, including iterative scaling.</font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2001</td>
<td><a href="ep/minka-ep-energy.pdf">The EP energy function and minimization schemes</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2001</td>
<td><a href="ep/">Expectation Propagation for approximate Bayesian inference</a></td>
<td><font size="-1">UAI version of my thesis, with some extra results.</font></td>
</tr>

<tr>
<td>E</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2001</td>
<td><a href="ep/">A family of algorithms for approximate Bayesian inference</a></td>
<td><font size="-1">(PhD thesis work) A powerful generalization of belief propagation.</font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2001</td>
<td><a href="rem.html">Using lower bounds to approximate integrals</a></td>
<td><font size="-1">A new interpretation and generalization of Variational Bayes.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td>O</td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="newton.html">Beyond Newton's method</a></td>
<td><font size="-1">Custom approximations for fast optimization.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td>O</td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="dirichlet/">Estimating a Dirichlet distribution</a></td>
<td><font size="-1">Optimization using Newton, modified Newton, and lower
bounds.</font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="pca/">Automatic choice of dimensionality for PCA</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="http://www.media.mit.edu/~tpminka/statlearn/demo/">Bayesian model selection</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="quadrature.html">Deriving quadrature rules from Gaussian processes</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="metric/">Distance measures as prior probabilities</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="bma.html">Bayesian model averaging is not model combination</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2000</td>
<td><a href="erm.html">Empirical Risk Minimization is an incomplete inductive principle</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>1999</td>
<td><a href="point-sets.html">Learning How to Learn is Learning With Point Sets</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>1999</td>
<td><a href="eiv.html">Linear regression with errors in both variables:
A proper Bayesian approach</a></td>
<td><font size="-1">Total least squares is not optimal.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>1999</td>
<td><a href="dirichlet/minka-dirtree.pdf">The Dirichlet-tree
distribution</a></td>
<td><font size="-1">The next time you use a Dirichlet, consider a Dirichlet-tree instead.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>2001</td>
<td><a href="ocr.html">
Document image decoding using iterated complete path search</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="http://vismod.media.mit.edu/tech-reports/TR-531-ABSTRACT.html">From Hidden Markov Models to Linear Dynamical Systems</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="multinomial.html">Bayesian inference, entropy, and the multinomial distribution</a></td>
<td><font size="-1">How empirical entropy and empirical mutual information can arise in Bayesian inference.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td>O</td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="em.html">Expectation-Maximization as lower bound maximization</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="linear.html">Bayesian linear regression</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="uniform.html">Bayesian inference of a uniform distribution</a></td>
<td><font size="-1">Bayesian methods succeed where maximum-likelihood does not.</font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="gaussian.html">Inferring a Gaussian distribution</a></td>
<td><font size="-1">Bayes provides a new approach to this age-old problem.</font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="diagrams.html">Independence Diagrams</a></td>
<td><font size="-1">A summary of Bayesian network notation.</font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="pathologies.html">Pathologies of Orthodox Statistics</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>1998</td>
<td><a href="nuances.html">Nuances of probability
theory</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td>B</td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>1998</td>
<td><a href="http://www.media.mit.edu/~tpminka/pichunter/">An Optimized Interaction Strategy for Bayesian Relevance Feedback</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td>M</td>
<td></td>
<td></td>
<td></td>
<td>1997</td>
<td><a href="matrix/">Old and New Matrix Algebra Useful for Statistics</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>1996</td>
<td><a href="http://vismod.media.mit.edu/tech-reports/TR-382-ABSTRACT.html">Modeling user subjectivity in image libraries</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>1996</td>
<td><a href="http://vismod.media.mit.edu/tech-reports/TR-365-ABSTRACT.html">An Image Database Browser that Learns from User Interaction</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>1997</td>
<td><a href="http://vismod.media.mit.edu/tech-reports/TR-349-ABSTRACT.html">Interactive Learning using a "Society of Models"</a></td>
<td><font size="-1"></font></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>V</td>
<td>1995</td>
<td><a href="http://pubs.media.mit.edu/?section=docdetail&id=215948&collection=Media+Lab&filtercollection=Media+Lab">Vision Texture for Annotation</a></td>
<td><font size="-1"></font></td>
</tr>


</table>

</body> </html>
