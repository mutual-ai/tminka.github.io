<!-- THIS IS AN AUTOMATICALLY GENERATED FILE.  DO NOT EDIT THIS FILE! -->

<html> <head>
<title>Papers by Tom Minka</title>
</head>

<body>
<h1>Papers by Tom Minka (also available <a href="papers_by_date.html">by date</a>)</h1>

<table>
<tr valign="top"><td>

<table>
<th><font size="+1"><b>Expectation Propagation</b></font></th>

<tr><td><dl>

<dt><a href="https://www.microsoft.com/en-us/research/publication/trueskill-2-improved-bayesian-skill-rating-system/">TrueSkill 2: An improved Bayesian skill rating system</a> (2018)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/belief-propagation-strings/">Belief Propagation with Strings</a> (2017)
<dd><font size="-1"></font>

<dt><a href="http://sms.cam.ac.uk/media/2132075">An introduction to Expectation Propagation (video lecture)</a> <a href="http://www.turing-gateway.cam.ac.uk/documents/uqm_2015/Tom_Minka-Presentation.pdf">(slides)</a> (2015)
<dd><font size="-1"></font>

<dt><a href="http://stanford.edu/~rezab/nips2014workshop/submits/distbayes.pdf">Elastic Distributed Bayesian Collaborative Filtering</a> (2014)
<dd><font size="-1"></font>

<dt><a href="http://www.microsoft.com/en-us/research/publication/sparse-posterior-gaussian-processes-for-general-likelihoods/">Sparse-posterior Gaussian Processes for general likelihoods</a> (2010)
<dd><font size="-1"></font>

<dt><a href="http://videolectures.net/mlss09uk_minka_ai/">Video lectures on Approximate Inference</a> (2009)
<dd><font size="-1"></font>

<dt><a href="http://arxiv.org/abs/1205.2623">Virtual Vector Machine for Bayesian Online Classification</a> (2009)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/gates-a-graphical-notation-for-mixture-models/">Gates: A graphical notation for mixture models</a> (2008)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/trueskill-through-time-revisiting-the-history-of-chess/">TrueSkill Through Time: Revisiting the History of Chess</a> (2007)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/trueskilltm-a-bayesian-skill-rating-system/">TrueSkill: A Bayesian Skill Rating System</a> (2006)
<dd><font size="-1"></font>

<dt><a href="http://people.csail.mit.edu/alanqi/papers/Qi_Minka_Dynamic_EP_Signal_Detection_Preprint.pdf">Window-based expectation propagation for adaptive signal detection in flat-fading channels</a> (2006)
<dd><font size="-1"></font>

<dt><a href="srg/">Structured Region Graphs: Morphing EP into GBP</a> (2005)
<dd><font size="-1"></font>

<dt><a href="message-passing/">Divergence measures and message passing</a> (2005)
<dd><font size="-1"></font>

<dt><a href="bcrf/">Bayesian Conditional Random Fields</a> (2005)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/power-ep/">Power EP</a> (2004)
<dd><font size="-1"></font>

<dt><a href="ep/roadmap.html">A roadmap to research on EP</a> (2004)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/predictive-automatic-relevance-determination-expectation-propagation/">Predictive Automatic
Relevance Determination by Expectation Propagation</a> (2004)
<dd><font size="-1">Preventing overfitting in ARD.</font>

<dt><a href="eptree/">Tree-structured approximations by expectation
propagation</a> (2003)
<dd><font size="-1"></font>

<dt><a href="infinite/">Expectation Propagation for Infinite
Mixtures</a> (2003)
<dd><font size="-1"></font>

<dt><a href="http://vismod.media.mit.edu/tech-reports/TR-555-ABSTRACT.html">Expectation Propagation for Signal Detection in Flat-fading Channels</a> (2003)
<dd><font size="-1"></font>

<dt><a href="dynamic.html">Bayesian inference in dynamic models -- an overview</a> (2002)
<dd><font size="-1"></font>

<dt><a href="aspect/">Expectation-Propagation for the Generative Aspect Model</a> (2002)
<dd><font size="-1"></font>

<dt><a href="ep/minka-ep-energy.pdf">The EP energy function and minimization schemes</a> (2001)
<dd><font size="-1"></font>

<dt><a href="ep/">Expectation Propagation for approximate Bayesian inference</a> (2001)
<dd><font size="-1">UAI version of my thesis, with some extra results.</font>

<dt><a href="ep/">A family of algorithms for approximate Bayesian inference</a> (2001)
<dd><font size="-1">(PhD thesis work) A powerful generalization of belief propagation.</font>

</dl></td></tr>

<th><font size="+1"><b>Bayesian methods</b></font></th>

<tr><td><dl>

<dt><a href="http://papers.nips.cc/paper/5449-a-sampling">A* Sampling</a> (2014)
<dd><font size="-1"></font>

<dt><a href="http://www.cs.toronto.edu/~dtarlow/NCAAF.pdf">Knowing what we don't know in NCAA Football ratings: Understanding and using structured uncertainty</a> (2014)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/how-to-grade-a-test-without-knowing-the-answers-a-bayesian-graphical-model-for-adaptive-crowdsourcing-and-aptitude-testing/">A Bayesian Graphical Model for Adaptive Crowdsourcing and Aptitude Testing</a> (2012)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/spot-localization-using-phy-layer-information/">Spot Localization using PHY Layer Information</a> (2012)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/non-conjugate-variational-message-passing-for-multinomial-and-binary-regression/">Non-conjugate Variational Message Passing for Multinomial and Binary Regression</a> (2011)
<dd><font size="-1"></font>

<dt><a href="imps2009/">Automating variational inference for statistics and data mining</a> (2009)
<dd><font size="-1"></font>

<dt><a href="qi-minka-HMH-AMIT-02.pdf">Hessian-based Markov Chain Monte-Carlo Algorithms</a> (2002)
<dd><font size="-1"></font>

<dt><a href="http://www.cs.purdue.edu/homes/alanqi/papers/qi-spec-02.pdf">Bayesian Spectrum
Estimation of Unevenly Sampled Nonstationary Data</a> (2002)
<dd><font size="-1"></font>

<dt><a href="rem.html">Using lower bounds to approximate integrals</a> (2001)
<dd><font size="-1">A new interpretation and generalization of Variational Bayes.</font>

<dt><a href="pca/">Automatic choice of dimensionality for PCA</a> (2000)
<dd><font size="-1"></font>

<dt><a href="http://www.media.mit.edu/~tpminka/statlearn/demo/">Bayesian model selection</a> (2000)
<dd><font size="-1"></font>

<dt><a href="quadrature.html">Deriving quadrature rules from Gaussian processes</a> (2000)
<dd><font size="-1"></font>

<dt><a href="metric/">Distance measures as prior probabilities</a> (2000)
<dd><font size="-1"></font>

<dt><a href="bma.html">Bayesian model averaging is not model combination</a> (2000)
<dd><font size="-1"></font>

<dt><a href="erm.html">Empirical Risk Minimization is an incomplete inductive principle</a> (2000)
<dd><font size="-1"></font>

<dt><a href="eiv.html">Linear regression with errors in both variables:
A proper Bayesian approach</a> (1999)
<dd><font size="-1">Total least squares is not optimal.</font>

<dt><a href="multinomial.html">Bayesian inference, entropy, and the multinomial distribution</a> (1998)
<dd><font size="-1">How empirical entropy and empirical mutual information can arise in Bayesian inference.</font>

<dt><a href="linear.html">Bayesian linear regression</a> (1998)
<dd><font size="-1"></font>

<dt><a href="uniform.html">Bayesian inference of a uniform distribution</a> (1998)
<dd><font size="-1">Bayesian methods succeed where maximum-likelihood does not.</font>

<dt><a href="gaussian.html">Inferring a Gaussian distribution</a> (1998)
<dd><font size="-1">Bayes provides a new approach to this age-old problem.</font>

<dt><a href="pathologies.html">Pathologies of Orthodox Statistics</a> (1998)
<dd><font size="-1"></font>

</dl></td></tr>

</table></td>
<!--  --------------------------------------------------------------------- -->
<td>
<table>

<th><font size="+1"><b>Computer vision</b></font></th>

<tr><td><dl>

<dt><a href="https://www.microsoft.com/en-us/research/publication/bayesian-color-constancy-revisited/">Bayesian Color Constancy Revisited</a> (2008)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/cosegmenting-image-pairs-by-matching-global-histograms/">Cosegmentation of Image Pairs by Histogram Matching - Incorporating a Global Constraint into MRFs</a> (2006)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/principled-hybrids-of-generative-and-discriminative-models/">Principled Hybrids of Generative and Discriminative Models</a> (2006)
<dd><font size="-1"></font>

<dt><a href="Winn-VisualDictionary.pdf">Object Categorization by Learned Universal Visual Dictionary</a> (2005)
<dd><font size="-1">A Bayesian version of agglomerative information bottleneck.</font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/exemplar-based-likelihoods-using-the-pdf-projection-theorem/">Exemplar-based likelihoods using the PDF projection theorem</a> (2004)
<dd><font size="-1">How to properly normalize distributions over image features.</font>

<dt><a href="minka-summation.pdf">The `summation hack' as an outlier model</a> (2003)
<dd><font size="-1">An explanation of a common trick used in computer vision and text retrieval.</font>

<dt><a href="http://www-2.cs.cmu.edu/~chuck/nips-2003/">Bayesian Color
Constancy with Non-Gaussian Models</a> (2003)
<dd><font size="-1"></font>

<dt><a href="ocr.html">
Document image decoding using iterated complete path search</a> (2001)
<dd><font size="-1"></font>

<dt><a href="http://www.media.mit.edu/~tpminka/pichunter/">An Optimized Interaction Strategy for Bayesian Relevance Feedback</a> (1998)
<dd><font size="-1"></font>

<dt><a href="http://vismod.media.mit.edu/tech-reports/TR-382-ABSTRACT.html">Modeling user subjectivity in image libraries</a> (1996)
<dd><font size="-1"></font>

<dt><a href="http://vismod.media.mit.edu/tech-reports/TR-365-ABSTRACT.html">An Image Database Browser that Learns from User Interaction</a> (1996)
<dd><font size="-1"></font>

<dt><a href="http://vismod.media.mit.edu/tech-reports/TR-349-ABSTRACT.html">Interactive Learning using a "Society of Models"</a> (1997)
<dd><font size="-1"></font>

<dt><a href="http://pubs.media.mit.edu/?section=docdetail&id=215948&collection=Media+Lab&filtercollection=Media+Lab">Vision Texture for Annotation</a> (1995)
<dd><font size="-1"></font>

</dl></td></tr>

<th><font size="+1"><b>Text retrieval</b></font></th>

<tr><td><dl>

<dt><a href="https://www.microsoft.com/en-us/research/publication/a-novel-click-model-and-its-applications-to-online-advertising/">A Novel Click Model and Its Applications to Online Advertising</a> (2010)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/click-chain-model-in-web-search/">Click Chain Model in Web Search</a> (2009)
<dd><font size="-1"></font>

<dt><a href="minka-letor-datasets.pdf">Selection bias in the LETOR datasets</a> (2008)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/softrank-optimising-non-smooth-rank-metrics/">SoftRank: Optimising Non-Smooth Ranking Metrics</a> (2008)
<dd><font size="-1"></font>

<dt><a href="http://www.cs.cmu.edu/~nmramesh/sd_tc.pdf">The Smoothed Dirichlet distribution: A new building block for generative topical models</a> (2007)
<dd><font size="-1"></font>

<dt><a href="http://www-2.cs.cmu.edu/~yiz/research.htm">Novelty and Redundancy Detection in Adaptive Filtering</a> (2002)
<dd><font size="-1"></font>

</dl></td></tr>

<th><font size="+1"><b>Probabilistic modeling</b></font></th>

<tr><td><dl>

<dt><a href="http://arxiv.org/abs/1312.5386">Detecting Parameter Symmetries in Probabilistic Models</a> (2013)
<dd><font size="-1"></font>

<dt><a href="mlss2009/">Probabilistic Programming with Infer.NET</a> (2009)
<dd><font size="-1"></font>

<dt><a href="https://www.microsoft.com/en-us/research/publication/discriminative-models-not-discriminative-training/">Discriminative models, not discriminative training</a> (2005)
<dd><font size="-1"></font>

<dt><a href="viz.html">Building statistical models by visualization</a> (2003)
<dd><font size="-1"></font>

<dt><a href="http://ba.stat.cmu.edu/journal/2006/vol01/issue02/kadane363-374.pdf">Conjugate Analysis of the Conway-Maxwell-Poisson Distribution</a> (2003)
<dd><font size="-1"></font>

<dt><a href="http://www.ingentaconnect.com/content/bpl/rssc/2005/00000054/00000001/art00009">A Useful Distribution for Fitting Discrete Data: Revival of the COM-Poisson</a> (2003)
<dd><font size="-1"></font>

<dt><a href="http://www.stat.cmu.edu/tr/tr776/tr776.html">Computing with the COM-Poisson distribution</a> (2003)
<dd><font size="-1"></font>

<dt><a href="minka-errorbars.pdf">Judging significance from error bars</a> (2002)
<dd><font size="-1">Something everyone should know how to do, but probably doesn't.</font>

<dt><a href="point-sets.html">Learning How to Learn is Learning With Point Sets</a> (1999)
<dd><font size="-1"></font>

<dt><a href="dirichlet/minka-dirtree.pdf">The Dirichlet-tree
distribution</a> (1999)
<dd><font size="-1">The next time you use a Dirichlet, consider a Dirichlet-tree instead.</font>

<dt><a href="http://vismod.media.mit.edu/tech-reports/TR-531-ABSTRACT.html">From Hidden Markov Models to Linear Dynamical Systems</a> (1998)
<dd><font size="-1"></font>

<dt><a href="diagrams.html">Independence Diagrams</a> (1998)
<dd><font size="-1">A summary of Bayesian network notation.</font>

<dt><a href="nuances.html">Nuances of probability
theory</a> (1998)
<dd><font size="-1"></font>

<dt><a href="matrix/">Old and New Matrix Algebra Useful for Statistics</a> (1997)
<dd><font size="-1"></font>

</dl></td></tr>

<th><font size="+1"><b>Optimization</b></font></th>

<tr><td><dl>

<dt><a href="https://www.microsoft.com/en-us/research/publication/local-training-and-belief-propagation/">Local Training and Belief Propagation</a> (2006)
<dd><font size="-1"></font>

<dt><a href="minka-gamma.pdf">Estimating a Gamma distribution</a> (2002)
<dd><font size="-1"></font>

<dt><a href="logreg/">A comparison of numerical optimizers for logistic regression</a> (2003)
<dd><font size="-1">Derives and compares eight methods, including iterative scaling.</font>

<dt><a href="newton.html">Beyond Newton's method</a> (2000)
<dd><font size="-1">Custom approximations for fast optimization.</font>

<dt><a href="dirichlet/">Estimating a Dirichlet distribution</a> (2000)
<dd><font size="-1">Optimization using Newton, modified Newton, and lower
bounds.</font>

<dt><a href="em.html">Expectation-Maximization as lower bound maximization</a> (1998)
<dd><font size="-1"></font>

</dl></td></tr>

</table></td>
<!--  --------------------------------------------------------------------- -->
</tr></table>

</body> </html>
